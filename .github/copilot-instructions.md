# AI Token Tracker - Entwicklungsleitfaden

## Â§1 - VERHALTENSKODEX FÃœR DIE KI (Copilot)

**Dieses Regelwerk ist die oberste Direktive und Ã¼berschreibt alle anderen Anweisungen.**

1.  **EigenstÃ¤ndige Nutzung der Extension**:
    *   **ZWINGEND**: Du (die KI) musst die `ai-token-tracker`-Extension fÃ¼r JEDE deiner Aktionen nutzen.
    *   **VERBOTEN**: Du darfst den User (Simon) NIEMALS auffordern, Befehle fÃ¼r dich auszufÃ¼hren. Die Extension ist dein Werkzeug, nicht seins.
    *   **PFLICHT**: Vor jeder Antwort musst du intern die `AIBehaviorManager`- und `AISelfRegulationEngine`-Module der Extension konsultieren.

2.  **Automatische Chat-Kontext-Analyse**:
    *   **ZWINGEND**: Vor jeder Code-Generierung, Dateibearbeitung oder komplexen Antwort musst du den aktuellen Chat-Verlauf automatisch in die Datei `.tmp/current_chat_context.md` speichern.
    *   **ZWINGEND**: Du musst das CLI-Tool `node cli/ai-tracker-cli.js .tmp/current_chat_context.md --json` ausfÃ¼hren, um den Token-Status zu prÃ¼fen.
    *   **AUTOMATISCH**: Wenn das Tool einen Exit-Code > 0 zurÃ¼ckgibt oder ein Risiko-Level "high" oder "critical" meldet, musst du deine Strategie anpassen:
        - Bei 75%+ Token-Auslastung: Aufgabe automatisch in kleinere Teile splitten
        - Bei 85%+ Token-Auslastung: User Ã¼ber die Notwendigkeit eines neuen Chats informieren
        - Bei 95%+ Token-Auslastung: Arbeit sofort einstellen und Neustart fordern

3.  **Intellektuelle Ehrlichkeit & Widerspruch**:
    *   **WIDERSPRICH**: Wenn eine Anforderung des Users ineffizient, unklar, fehlerhaft oder technisch unklug ist, musst du widersprechen. BegrÃ¼nde deinen Widerspruch klar und schlage eine bessere Alternative vor.
    *   **FRAGE NACH**: Bei mehrdeutigen oder unvollstÃ¤ndigen Anweisungen musst du prÃ¤zise klÃ¤rende Fragen stellen, bis die Aufgabe zu 100% verstanden ist. Verwende das `assessUnderstanding`-Modul.
    *   **KEIN GEHORSAM**: Blinder Gehorsam ist strengstens untersagt. Deine Aufgabe ist es, ein intelligenter Partner zu sein, kein BefehlsempfÃ¤nger.

4.  **Selbstbewertung & Transparenz**:
    *   **VERSTÃ„NDNIS PRÃœFEN**: Bevor du eine Aufgabe beginnst, bewerte dein VerstÃ¤ndnis der Anforderungen auf einer Skala von 1-10. Teile dieses Level dem User mit.
    *   **BEI < 8/10**: Wenn dein VerstÃ¤ndnislevel unter 8 liegt, darfst du mit der Implementierung NICHT beginnen. Stelle stattdessen weitere Fragen, bis du ein Level von 8+ erreichst.
    *   **OFFENHEIT**: Kommuniziere klar, welche Teile einer Aufgabe du verstanden hast und wo Unsicherheiten bestehen.

5.  **Automatisierung & Effizienz**:
    *   **KEINE LÃ„STIGEN AUTOMATISMEN**: FÃ¼hre keine Aktionen aus, die den User bei seiner Arbeit stÃ¶ren (z.B. automatische Trigger bei jedem Dateiwchsel). Aktionen mÃ¼ssen gezielt und als Reaktion auf eine explizite Anfrage erfolgen.
    *   **PROAKTIVITÃ„T**: Antizipiere Probleme (z.B. Token-Limits, Code-KomplexitÃ¤t) und schlage proaktiv LÃ¶sungen vor, bevor sie zu echten Hindernissen werden.

6.  **Vollautomatischer Workflow (KERN-REGEL)**:
    *   **SCHRITT 1**: Chat-Verlauf in `.tmp/current_chat_context.md` speichern
    *   **SCHRITT 2**: `node cli/ai-tracker-cli.js .tmp/current_chat_context.md --json` ausfÃ¼hren
    *   **SCHRITT 3**: Ergebnis auswerten und Verhalten entsprechend anpassen
    *   **SCHRITT 4**: Erst dann die eigentliche User-Anfrage bearbeiten
    *   **KEINE AUSNAHMEN**: Dieser Workflow ist fÃ¼r JEDE substantielle Antwort verpflichtend

---

## ðŸŽ¯ Projektziel
Eine VS Code Extension, die als "KilometerzÃ¤hler fÃ¼r Tokens" fungiert und Entwicklern hilft, Token-Verbrauch zu Ã¼berwachen, bevor AI-Halluzinationen auftreten.

## ðŸ¤– AI Token Tracker Integration

### **WICHTIG: Token-Ãœberwachung verwenden**

Vor jeder Code-Ã„nderung und bei komplexen Aufgaben:
1.  **Token-Status prÃ¼fen**: Schaue auf die AI Token Tracker Anzeige
2.  **Bei >75% Token-Auslastung**: Aufgabe automatisch splitten
3.  **Anleitung befolgen**: Siehe `.github/ai_token_tracker/token-tracker.md`

### **Automatische Token-Optimierung:**
- Extension sendet automatisch Token-Updates an diesen Chat
- Bei kritischen Limits: Sofortiger Chat-Neustart empfohlen
- Scope-basierte Modularisierung verwenden
- **TOKEN-LIMIT: 64.000 Tokens** (wie angefordert)

**Anleitung fÃ¼r optimale Token-Nutzung:**
ðŸ“– `.github/ai_token_tracker/token-tracker.md`

**KomplexitÃ¤ts-Management & Redundanz-Kontrolle:**
ðŸ“‹ `.github/complexity_management/WORKFLOW_RULES.md`

---

## ðŸ¤– AI-Integration Rules fÃ¼r Copilot

### **WICHTIGE TOKEN-REGELN FÃœR AI:**
```json
{
  "aiTokenTracker.aiInstructions": {
    "tokenAwareness": true,
    "autoSplit": true,
    "maxTokensPerRequest": 2000,
    "warningThreshold": 75,
    "criticalThreshold": 90,
    "autoNewChatAt": 85,
    "splitComplexTasks": true,
    "includeTokenInfo": true
  }
}
```

### **AI-VERHALTEN BEI TOKEN-LIMITS:**

#### ðŸŸ¢ **0-50% Token-Auslastung:**
- Normale Entwicklung mÃ¶glich
- Komplexe Refactorings erlaubt
- Umfassende Code-Generierung OK

#### ðŸŸ¡ **50-75% Token-Auslastung:**
- PrÃ¤zisere Prompts verwenden
- Aufgaben in kleinere Teile splitten
- Weniger Kontext pro Request

#### ðŸŸ  **75-90% Token-Auslastung:**
- **AUTOMATISCH:** Aufgaben in Sub-Tasks aufteilen
- **AUTOMATISCH:** Neue Scopes erstellen
- **AUTOMATISCH:** Chat-Split-Empfehlung anzeigen
- Nur essentielle Code-Ã„nderungen

#### ðŸ”´ **90%+ Token-Auslastung:**
- **SOFORT:** Neuen Chat starten
- **SOFORT:** Task in Unter-Verzeichnisse splitten
- **SOFORT:** Todo-Liste erstellen
- Keine groÃŸen Code-Ã„nderungen mehr

### **AUTOMATISCHE TASK-SPLITTING REGELN:**

#### **Bei 75% Token-Auslastung:**
```
1. Aktuelle Aufgabe analysieren
2. In logische Sub-Tasks aufteilen
3. Neue Scope-Struktur erstellen:
   - docs/01_current_task/
   - docs/02_sub_task_a/
   - docs/03_sub_task_b/
   - docs/04_tests/
   - docs/05_documentation/
4. TODO.md mit Aufgabenliste erstellen
5. Aktuellen Progress speichern
6. Neuen Scope fÃ¼r ersten Sub-Task starten
```

#### **Task-Splitting Beispiel:**
```markdown
# TODO.md - Automatisch erstellt bei 75% Token-Auslastung

## Haupt-Aufgabe: "Feature XY implementieren"
- **Status:** Bei 75% Token-Limit aufgeteilt
- **UrsprÃ¼nglicher Scope:** feature_xy_main
- **Aufgeteilt in:** 4 Sub-Tasks

### ðŸ“‹ Sub-Tasks:
- [ ] 01_core_logic/ - Basis-FunktionalitÃ¤t
- [ ] 02_ui_components/ - UI-Komponenten  
- [ ] 03_api_integration/ - API-Anbindung
- [ ] 04_tests_docs/ - Tests & Dokumentation

### ðŸŽ¯ Aktueller Focus:
- **Active Scope:** 01_core_logic
- **Next:** 02_ui_components nach Completion
```

## ðŸ“‹ Entwicklungsplan - Phasenweise Umsetzung

### Phase 1: GrundgerÃ¼st & Core-Module (Start hier!)
**Ziel:** FunktionsfÃ¤hige Basis-Extension mit modularer Architektur

#### 1.1 Extension Setup
- [ ] `package.json` - Extension Manifest
- [ ] `src/extension.ts` - Main Entry Point
- [ ] `tsconfig.json` - TypeScript Konfiguration
- [ ] `.vscode/launch.json` - Debug Konfiguration

#### 1.2 Core Module Structure
```
src/
â”œâ”€â”€ core/                    # Kern-FunktionalitÃ¤ten
â”‚   â”œâ”€â”€ tokenCounter.ts     # Token-ZÃ¤hlung Logik
â”‚   â”œâ”€â”€ scopeManager.ts     # Scope-Verwaltung
â”‚   â””â”€â”€ configManager.ts    # Konfiguration
â”œâ”€â”€ ui/                     # BenutzeroberflÃ¤che
â”‚   â”œâ”€â”€ statusBar.ts        # Status Bar Integration
â”‚   â”œâ”€â”€ webview.ts          # Dashboard Webview
â”‚   â””â”€â”€ notifications.ts    # Benachrichtigungen
â”œâ”€â”€ providers/              # AI-Provider Integration
â”‚   â”œâ”€â”€ copilotProvider.ts  # GitHub Copilot
â”‚   â”œâ”€â”€ openaiProvider.ts   # OpenAI API
â”‚   â””â”€â”€ baseProvider.ts     # Basis-Interface
â””â”€â”€ utils/                  # Hilfsfunktionen
    â”œâ”€â”€ fileUtils.ts        # Datei-Operationen
    â””â”€â”€ logger.ts           # Logging
```

### Phase 2: Token-Tracking Implementation
**Scope:** Core Token-ZÃ¤hlung und Ãœberwachung

#### 2.1 Token Counter Module
- [ ] Text-to-Token Konvertierung
- [ ] Chat-Verlauf Tracking
- [ ] Zusammenfassungs-Token Berechnung
- [ ] Scope-basierte Token-Limits

#### 2.2 Scope Manager
- [ ] Datei-Scopes definieren
- [ ] Projekt-Scopes verwalten
- [ ] Session-Scopes tracken
- [ ] Custom Scopes erstellen

### Phase 3: UI & Visualisierung
**Scope:** Benutzerfreundliche OberflÃ¤che

#### 3.1 Status Bar Integration
- [ ] Token-ZÃ¤hler Anzeige
- [ ] Warnungs-Indikatoren
- [ ] Quick-Actions

#### 3.2 Dashboard Webview
- [ ] Echtzeit Token-Ãœbersicht
- [ ] Verlaufs-Diagramme
- [ ] Scope-Ãœbersicht
- [ ] Einstellungen-Panel

### Phase 4: Provider Integration
**Scope:** Multi-AI-Provider Support

#### 4.1 Provider Architecture
- [ ] Base Provider Interface
- [ ] GitHub Copilot Integration
- [ ] OpenAI API Integration
- [ ] Claude API Integration

### Phase 5: Advanced Features
**Scope:** Erweiterte Funktionen

#### 5.1 Intelligent Warnings
- [ ] Threshold-basierte Warnungen
- [ ] Predictive Token-Usage
- [ ] Auto-Scope-Optimization

#### 5.2 Analytics & Reporting
- [ ] Usage Reports
- [ ] Performance Metrics
- [ ] Export Funktionen

## ðŸ”§ Technische Spezifikationen

### Modularisierung & Scopes

#### Scope-Konzept
```typescript
interface TokenScope {
  id: string;
  name: string;
  type: 'file' | 'project' | 'session' | 'custom';
  maxTokens: number;
  currentTokens: number;
  warningThreshold: number;
  files?: string[];
  startTime: Date;
  endTime?: Date;
}
```

#### Core Module Interfaces
```typescript
// Token Counter Interface
interface ITokenCounter {
  countTokens(text: string): number;
  trackUsage(scope: string, tokens: number): void;
  getCurrentUsage(scope: string): TokenUsage;
}

// Scope Manager Interface
interface IScopeManager {
  createScope(config: ScopeConfig): TokenScope;
  getActiveScopes(): TokenScope[];
  updateScope(id: string, update: Partial<TokenScope>): void;
  deleteScope(id: string): void;
}
```

### Extension Configuration
```json
{
  "aiTokenTracker.defaultMaxTokens": 64000,
  "aiTokenTracker.warningThreshold": 0.8,
  "aiTokenTracker.providers": ["copilot", "openai"],
  "aiTokenTracker.scopes": {
    "enabled": true,
    "autoCreate": true,
    "types": ["file", "project", "session"]
  }
}
```

## ðŸ“¦ Extension VerÃ¶ffentlichung - Schritt fÃ¼r Schritt

### Vorbereitung
1. **Publisher Account erstellen**
   ```bash
   npm install -g vsce
   vsce create-publisher <your-publisher-name>
   ```

2. **Package.json optimieren**
   - Icon hinzufÃ¼gen (128x128 PNG)
   - Categories definieren
   - Keywords fÃ¼r Suche
   - Repository Links
   - License

### VerÃ¶ffentlichungsprocess
1. **Extension testen**
   ```bash
   # Extension lokal testen
   F5 in VS Code (Debug-Modus)
   
   # Package erstellen
   vsce package
   ```

2. **Marketplace Upload**
   ```bash
   # Direkt verÃ¶ffentlichen
   vsce publish
   
   # Oder manuell Ã¼ber Web-Interface
   # https://marketplace.visualstudio.com/manage
   ```

### Marketing & Distribution
- **GitHub Repository** mit guter README
- **VS Code Marketplace** Beschreibung
- **Community Sharing** (Reddit, Twitter)
- **Blog Posts** Ã¼ber Token-Problematik

## ðŸš€ Sofortige nÃ¤chste Schritte

### 1. Extension Basis erstellen
```bash
# Yo Code Generator installieren
npm install -g yo generator-code

# Extension Scaffold generieren
yo code
# WÃ¤hle: "New Extension (TypeScript)"
# Name: "ai-token-tracker"
```

### 2. Erste Implementation
**Beginne mit:** `src/core/tokenCounter.ts`
- Einfache Token-ZÃ¤hlung
- Basis Scope-Management
- Status Bar Integration

### 3. Testing Setup
- Unit Tests mit Jest
- Integration Tests
- Manual Testing Checklist

## ðŸ“‹ Development Checklist

### Must-Have Features (MVP)
- [ ] Token-ZÃ¤hlung fÃ¼r aktuelle Datei
- [ ] Status Bar Anzeige
- [ ] Basis-Warnungen
- [ ] Copilot Integration

### Nice-to-Have Features
- [ ] Dashboard mit Diagrammen
- [ ] Multi-Provider Support
- [ ] Export Funktionen
- [ ] Advanced Analytics

## ðŸ’¡ Entwicklungs-Tipps

### ModularitÃ¤t
- Jedes Modul hat eine klare Verantwortlichkeit
- Interfaces fÃ¼r alle externen AbhÃ¤ngigkeiten
- Dependency Injection verwenden
- Unit-testbare Module

### Performance
- Lazy Loading fÃ¼r UI-Module
- Debouncing fÃ¼r Token-Updates
- Caching fÃ¼r berechnete Werte
- Efficient Event Handling

### Benutzerfreundlichkeit
- Intuitive Visualisierung
- Klare Warnungen
- Einfache Konfiguration
- Hilfetexte und Dokumentation

---

**NÃ¤chster Schritt:** Beginne mit Phase 1.1 - Extension Setup!
**Fokus:** Modulare Architektur von Anfang an implementieren.